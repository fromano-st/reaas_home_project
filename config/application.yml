# E-commerce Streaming ETL Pipeline Configuration
# This file contains all configurable parameters for the pipeline

# Kafka Configuration
kafka:
  bootstrap_servers: "localhost:9092"
  topics:
    transactions: "ecommerce-transactions"
    aggregations: "ecommerce-aggregations"
  producer:
    acks: "all"
    retries: 3
    batch_size: 16384
    linger_ms: 10
    buffer_memory: 33554432
    compression_type: "snappy"
  consumer:
    group_id: "spark-streaming-consumer"
    auto_offset_reset: "latest"
    enable_auto_commit: false

# Spark Configuration
spark:
  app_name: "EcommerceStreamingETL"
  master: "local[*]"
  driver_memory: "2g"
  executor_memory: "2g"
  sql:
    adaptive:
      enabled: true
      coalescePartitions:
        enabled: true
      skewJoin:
        enabled: true
  streaming:
    checkpointLocation: "/tmp/spark-checkpoint"
    processingTime: "30 seconds"
    maxOffsetsPerTrigger: 1000000

# AWS S3 Configuration
aws:
  region: "us-east-1"
  s3:
    bucket: "ecommerce-data-lake"
    paths:
      transactions: "transactions/"
      delta: "delta/transactions/"
      checkpoints: "checkpoints/"
      analytics: "analytics/"
  credentials:
    provider: "org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider"

# Data Processing Configuration
processing:
  windowing:
    duration: "5 minutes"
    watermark: "10 minutes"
  partitioning:
    columns: ["year", "month", "day"]
  quality:
    filters:
      min_amount: 0.01
      max_amount: 10000.0
      min_quantity: 1
      max_quantity: 100

# Producer Configuration
producer:
  rate_per_second: 10.0
  metrics_port: 8000
  duration_seconds: null  # null for infinite
  data_generation:
    fraud_rate: 0.02
    categories:
      - "Electronics"
      - "Clothing"
      - "Home & Garden"
      - "Books"
      - "Sports"
    payment_methods:
      - "credit_card"
      - "debit_card"
      - "paypal"
      - "apple_pay"
      - "google_pay"
      - "bank_transfer"
    device_types:
      - "mobile"
      - "desktop"
      - "tablet"

# Monitoring Configuration
monitoring:
  prometheus:
    port: 9090
    scrape_interval: "15s"
  grafana:
    port: 3000
    admin_password: "admin"
  jmx_exporter:
    port: 5556
  kafka_ui:
    port: 8080

# Analytics Configuration
analytics:
  percentile_analysis:
    percentile: 0.95
    outlier_threshold: 3  # standard deviations
    min_events_per_day: 500
  output_formats:
    - "parquet"
    - "csv"
  performance:
    cache_enabled: true
    repartition_enabled: true

# Logging Configuration
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "pipeline.log"

# Development Configuration
development:
  local_data_path: "data/"
  test_data_size: 1000
  debug_mode: false