name: CI - Main Branch

on:
  push:
    branches:
      - main
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.11'
  TERRAFORM_VERSION: '1.11.0'

jobs:
  lint-and-format:
    name: Lint and Format
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r src/producer/requirements.txt
        pip install -r src/streaming/requirements.txt
        pip install -r tests/requirements.txt

    - name: Set up Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TERRAFORM_VERSION }}

    - name: Install terraform formatting tools
      run: |
        curl -s https://raw.githubusercontent.com/terraform-linters/tflint/master/install_linux.sh | bash

    - name: Python Code Formatting Check
      run: |
        black --check --diff src/ tests/ docker/

    - name: Python Linting and Auto-fixes
      run: |
        echo "Linting Python code with ruff..."
        ruff check --fix src/ tests/ docker/

    - name: Terraform Formatting Check
      run: |
        cd infra/terraform
        terraform fmt -check -recursive

    - name: Terraform Linting
      run: |
        echo "Linting Terraform code..."
        cd infra/terraform
        tflint --init
        tflint

    - name: Terraform Validation
      run: |
        cd infra/terraform
        terraform init -backend=false
        terraform validate

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: lint-and-format

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r tests/requirements.txt
        pip install -r src/producer/requirements.txt
        pip install -r src/streaming/requirements.txt

    - name: Run Unit Tests
      run: |
        cd tests
        python -m pytest \
          -v --tb=short --cov=../src --cov-report=xml --cov-report=html \
          --junitxml=test-results.xml

    - name: Upload Test Results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results
        path: |
          tests/test-results.xml
          tests/htmlcov/
          tests/coverage.xml

    - name: Upload Coverage to Codecov
      uses: codecov/codecov-action@v3
      if: always()
      with:
        file: tests/coverage.xml
        flags: unittests
        name: codecov-umbrella

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests

    services:
      zookeeper:
        image: confluentinc/cp-zookeeper:7.4.0
        env:
          ZOOKEEPER_CLIENT_PORT: 2181
          ZOOKEEPER_TICK_TIME: 2000
        options: >-
          --health-cmd "echo ruok | nc localhost 2181"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      kafka:
        image: confluentinc/cp-kafka:7.4.0
        env:
          KAFKA_BROKER_ID: 1
          KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
          KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
          KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
          KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
          KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
          KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
          KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
          KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
        ports:
          - 9092:9092
        options: >-
          --health-cmd "kafka-topics --bootstrap-server localhost:9092 --list"
          --health-interval 30s
          --health-timeout 10s
          --health-retries 5

      minio:
        image: minio/minio
        env:
          MINIO_ROOT_USER: ${{ secrets.MINIO_ROOT_USER }}
          MINIO_ROOT_PASSWORD: ${{ secrets.MINIO_ROOT_PASSWORD }}
        ports:
          - 9000:9000
        options: >-
          --health-cmd "curl -f http://localhost:9000/minio/health/live"
          --health-interval 30s
          --health-timeout 20s
          --health-retries 3


    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r tests/requirements.txt
        pip install -r src/producer/requirements.txt
        pip install -r src/streaming/requirements.txt

    - name: Wait for services to be healthy
      run: |
        echo "Waiting for services to be ready..."

        # Wait for Kafka
        echo "Waiting for Kafka..."
        timeout 120 bash -c 'until nc -z localhost 9092; do sleep 2; done'

        # Wait for MinIO
        echo "Waiting for MinIO..."
        timeout 120 bash -c 'until curl -f http://localhost:9000/minio/health/live; do sleep 2; done'

        # Additional wait to ensure services are fully initialized
        sleep 10

        echo "All services are ready!"

    - name: Create .env file for testing
      run: |
        cat > .env << EOF
        # Kafka Configuration
        KAFKA_BOOTSTRAP_SERVERS=localhost:9092
        KAFKA_TOPIC=iot-events-test

        # Producer Configuration
        PRODUCER_INTERVAL=1.0

        # Spark Configuration
        CHECKPOINT_LOCATION=/tmp/spark-checkpoints-test
        OUTPUT_PATH=s3a://test-bucket-data/processed/

        # MinIO/S3 Configuration
        MINIO_ENDPOINT=http://localhost:9000
        AWS_ENDPOINT=http://localhost:9000
                AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}

        # S3 Buckets
        AWS_S3_BUCKET_LANDING=test-bucket-landing
        AWS_S3_BUCKET_DATA=test-bucket-data

        # Historical Data Configuration
        HISTORICAL_DAYS=1
        EOF

    - name: Test Kafka Connectivity
      run: |
        echo "Testing Kafka connectivity..."
        python3 -c "
        from kafka import KafkaAdminClient
        import sys
        try:
            admin = KafkaAdminClient(bootstrap_servers='localhost:9092', client_id='ci_test')
            topics = admin.list_topics()
            print(f'Kafka connection successful. Topics: {list(topics)}')
        except Exception as e:
            print(f'Kafka connection failed: {e}')
            sys.exit(1)
        "

    - name: Test S3/MinIO Connectivity
      run: |
        cd tests/s3_tester
        python test_s3.py

    - name: Test Producer Integration
      run: |
        echo "Testing producer..."
        cd src/producer
        timeout 30 python producer.py || echo "Producer test completed (timeout expected)"

    - name: Test Kafka-Spark Integration
      run: |
        echo "Testing Kafka-Spark integration..."
        python3 test_fix.py

  docker-build:
    name: Docker Build Test
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Build Producer image
      uses: docker/build-push-action@v5
      with:
        context: .
        dockerfile: ./docker/producer/Dockerfile
        push: false
        tags: iot-producer:test
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Build Streaming image
      uses: docker/build-push-action@v5
      with:
        context: .
        dockerfile: ./docker/streaming/Dockerfile  # Fixed: was using producer Dockerfile
        push: false
        tags: spark-streaming:test
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Build S3 Tester image
      uses: docker/build-push-action@v5
      with:
        context: ./tests/s3_tester
        push: false
        tags: s3-tester:test
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Test Docker Images
      run: |
        echo "Testing built Docker images..."

        # Test producer image
        docker run --rm iot-producer:test python3 -c "import producer; print('Producer image OK')"

        # Test s3-tester image
        docker run --rm s3-tester:test python3 -c "import test_s3; print('S3 tester image OK')"

  end-to-end-test:
    name: End-to-End Docker Test
    runs-on: ubuntu-latest
    needs: docker-build

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Create test environment
      run: |
        # Create directories
        mkdir -p tmp/spark-checkpoints
        chmod 777 tmp/spark-checkpoints

        # Create test .env
        cp .env .env.test

    - name: Run Docker Compose Test
      run: |
        echo "Running end-to-end Docker Compose test..."

        # Start infrastructure services
        docker-compose -f docker-compose-fixed.yml up -d zookeeper kafka minio

        # Wait for services
        sleep 60

        # Check service health
        docker-compose -f docker-compose-fixed.yml ps

        # Run S3 test
        docker-compose -f docker-compose-fixed.yml run --rm s3-tester

        # Start producer briefly
        docker-compose -f docker-compose-fixed.yml up -d iot-producer
        sleep 30

        # Check logs
        docker-compose -f docker-compose-fixed.yml logs iot-producer

        # Cleanup
        docker-compose -f docker-compose-fixed.yml down -v

  notify-success:
    name: Notify Success
    runs-on: ubuntu-latest
    needs: [lint-and-format, unit-tests, integration-tests, docker-build, end-to-end-test]
    if: success()

    steps:
    - name: Success Notification
      run: |
        echo "🎉 All CI checks passed successfully!"
        echo "✅ Lint and format checks passed"
        echo "✅ Unit tests passed"
        echo "✅ Integration tests passed"
        echo "✅ Docker images built successfully"
        echo "✅ End-to-end tests passed"
        echo "🚀 Ready for deployment"

  notify-failure:
    name: Notify Failure
    runs-on: ubuntu-latest
    needs: [lint-and-format, unit-tests, integration-tests, docker-build, end-to-end-test]
    if: failure()

    steps:
    - name: Failure Notification
      run: |
        echo "❌ CI pipeline failed!"
        echo "Please check the failed jobs and fix the issues."
        echo "Lint and Format: ${{ needs.lint-and-format.result }}"
        echo "Unit Tests: ${{ needs.unit-tests.result }}"
        echo "Integration Tests: ${{ needs.integration-tests.result }}"
        echo "Docker Build: ${{ needs.docker-build.result }}"
        echo "End-to-End Test: ${{ needs.end-to-end-test.result }}"
        exit 1