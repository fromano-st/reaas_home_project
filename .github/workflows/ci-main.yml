name: CI - Main Branch

on:
  push:
    branches:
      - main
  workflow_dispatch:

env:
  PYTHON_VERSION: '3.11'
  TERRAFORM_VERSION: '1.11.0'

jobs:
  lint-and-format:
    name: Lint and Format
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r src/producer/requirements.txt
        pip install -r src/streaming/requirements.txt
        pip install -r tests/requirements.txt

    - name: Set up Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TERRAFORM_VERSION }}

    - name: Install terraform formatting tools
      run: |
        curl -s https://raw.githubusercontent.com/terraform-linters/tflint/master/install_linux.sh | bash

    - name: Python Code Formatting Check
      run: |
        black --check --diff src/ tests/ docker/

    - name: Python Linting and Auto-fixes
      run: |
        echo "Linting Python code with ruff..."
        ruff check --fix src/ tests/ docker/

    - name: Terraform Formatting Check
      run: |
        cd infra/terraform
        terraform fmt -check -recursive

    - name: Terraform Linting
      run: |
        echo "Linting Terraform code..."
        cd infra/terraform
        tflint --init
        tflint

    - name: Terraform Validation
      run: |
        cd infra/terraform
        terraform init -backend=false
        terraform validate

  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: lint-and-format

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r tests/requirements.txt
        pip install -r src/producer/requirements.txt
        pip install -r src/streaming/requirements.txt

    - name: Run Unit Tests
      run: |
        cd tests
        python -m pytest \
          -v --tb=short --cov=../src --cov-report=xml --cov-report=html \
          --junitxml=test-results.xml

    - name: Upload Test Results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results
        path: |
          tests/test-results.xml
          tests/htmlcov/
          tests/coverage.xml

    - name: Upload Coverage to Codecov
      uses: codecov/codecov-action@v3
      if: always()
      with:
        file: tests/coverage.xml
        flags: unittests
        name: codecov-umbrella

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests

    services:
      zookeeper:
        image: confluentinc/cp-zookeeper:7.4.0
        env:
          ZOOKEEPER_CLIENT_PORT: 2181
          ZOOKEEPER_TICK_TIME: 2000
        options: >-
          --health-cmd "echo ruok | nc localhost 2181"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      kafka:
        image: confluentinc/cp-kafka:7.4.0
        env:
          KAFKA_BROKER_ID: 1
          KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
          KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
          KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
          KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
          KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
          KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
          KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
          KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
        ports:
          - 9092:9092
        options: >-
          --health-cmd "kafka-topics --bootstrap-server localhost:9092 --list"
          --health-interval 30s
          --health-timeout 10s
          --health-retries 5

      minio:
        image: minio/minio
        env:
          MINIO_ROOT_USER: ${{ secrets.MINIO_ROOT_USER }}
          MINIO_ROOT_PASSWORD: ${{ secrets.MINIO_ROOT_PASSWORD }}
        ports:
          - 9000:9000
        options: >-
          --health-cmd "curl -f http://localhost:9000/minio/health/live"
          --health-interval 30s
          --health-timeout 20s
          --health-retries 3


    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r tests/requirements.txt
        pip install -r src/producer/requirements.txt
        pip install -r src/streaming/requirements.txt

    - name: Wait for services to be healthy
      run: |
        echo "Waiting for services to be ready..."

        # Wait for Kafka
        echo "Waiting for Kafka..."
        timeout 120 bash -c 'until nc -z localhost 9092; do sleep 2; done'

        # Wait for MinIO
        echo "Waiting for MinIO..."
        timeout 120 bash -c 'until curl -f http://localhost:9000/minio/health/live; do sleep 2; done'

        # Additional wait to ensure services are fully initialized
        sleep 10

        echo "All services are ready!"

    - name: Create .env file for testing
      run: |
        cat > .env << EOF
        # Kafka Configuration
        KAFKA_BOOTSTRAP_SERVERS=localhost:9092
        KAFKA_TOPIC=iot-events-test

        # Producer Configuration
        PRODUCER_INTERVAL=1.0

        # Spark Configuration
        CHECKPOINT_LOCATION=/tmp/spark-checkpoints-test
        OUTPUT_PATH=s3a://test-bucket-data/processed/

        # MinIO/S3 Configuration
        MINIO_ENDPOINT=http://localhost:9000
        AWS_ENDPOINT=http://localhost:9000
                AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}

        # S3 Buckets
        AWS_S3_BUCKET_LANDING=test-bucket-landing
        AWS_S3_BUCKET_DATA=test-bucket-data

        # Historical Data Configuration
        HISTORICAL_DAYS=1
        EOF

    - name: Test Kafka Connectivity
      run: |
        echo "Testing Kafka connectivity..."
        python3 -c "
        from kafka import KafkaAdminClient
        import sys
        try:
            admin = KafkaAdminClient(bootstrap_servers='localhost:9092', client_id='ci_test')
            topics = admin.list_topics()
            print(f'Kafka connection successful. Topics: {list(topics)}')
        except Exception as e:
            print(f'Kafka connection failed: {e}')
            sys.exit(1)
        "

    - name: Test S3/MinIO Connectivity
      run: |
        cd tests/s3_tester
        python test_s3.py

    - name: Test Producer Integration
      run: |
        echo "Testing producer..."
        cd src/producer
        timeout 30 python producer.py || echo "Producer test completed (timeout expected)"

    - name: Test Kafka-Spark Integration
      run: |
        echo "Testing Kafka-Spark integration..."
        python3 test_fix.py

  docker-build:
    name: Docker Build Test
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Build Producer image
      uses: docker/build-push-action@v5
      with:
        context: .
        dockerfile: ./docker/producer/Dockerfile
        push: false
        tags: iot-producer:test
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Build Streaming image
      uses: docker/build-push-action@v5
      with:
        context: .
        dockerfile: ./docker/streaming/Dockerfile  # Fixed: was using producer Dockerfile
        push: false
        tags: spark-streaming:test
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Build S3 Tester image
      uses: docker/build-push-action@v5
      with:
        context: ./tests/s3_tester
        push: false
        tags: s3-tester:test
        cache-from: type=gha
        cache-to: type=gha,mode=max

    - name: Test Docker Images
      run: |
        echo "Testing built Docker images..."

        # Test producer image
        docker run --rm iot-producer:test python3 -c "import producer; print('Producer image OK')"

        # Test s3-tester image
        docker run --rm s3-tester:test python3 -c "import test_s3; print('S3 tester image OK')"

  end-to-end-test:
    name: End-to-End Docker Test
    runs-on: ubuntu-latest
    needs: docker-build

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Create test environment
      run: |
        # Create directories
        mkdir -p tmp/spark-checkpoints
        chmod 777 tmp/spark-checkpoints

        # Create test .env
        cp .env .env.test

    - name: Run Docker Compose Test
      run: |
        echo "Running end-to-end Docker Compose test..."

        # Start infrastructure services
        docker-compose -f docker-compose-fixed.yml up -d zookeeper kafka minio

        # Wait for services
        sleep 60

        # Check service health
        docker-compose -f docker-compose-fixed.yml ps

        # Run S3 test
        docker-compose -f docker-compose-fixed.yml run --rm s3-tester

        # Start producer briefly
        docker-compose -f docker-compose-fixed.yml up -d iot-producer
        sleep 30

        # Check logs
        docker-compose -f docker-compose-fixed.yml logs iot-producer

        # Cleanup
        docker-compose -f docker-compose-fixed.yml down -v

  notify-success:
    name: Notify Success
    runs-on: ubuntu-latest
    needs: [lint-and-format, unit-tests, integration-tests, docker-build, end-to-end-test]
    if: success()

    steps:
    - name: Success Notification
      run: |
        echo "ðŸŽ‰ All CI checks passed successfully!"
        echo "âœ… Lint and format checks passed"
        echo "âœ… Unit tests passed"
        echo "âœ… Integration tests passed"
        echo "âœ… Docker images built successfully"
        echo "âœ… End-to-end tests passed"
        echo "ðŸš€ Ready for deployment"

  notify-failure:
    name: Notify Failure
    runs-on: ubuntu-latest
    needs: [lint-and-format, unit-tests, integration-tests, docker-build, end-to-end-test]
    if: failure()

    steps:
    - name: Failure Notification
      run: |
        echo "âŒ CI pipeline failed!"
        echo "Please check the failed jobs and fix the issues."
        echo "Lint and Format: ${{ needs.lint-and-format.result }}"
        echo "Unit Tests: ${{ needs.unit-tests.result }}"
        echo "Integration Tests: ${{ needs.integration-tests.result }}"
        echo "Docker Build: ${{ needs.docker-build.result }}"
        echo "End-to-End Test: ${{ needs.end-to-end-test.result }}"
        exit 1